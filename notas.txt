links adc
https://github.com/afiskon/stm32-adc-dac/tree/master/Src

Donkey car github
https://github.com/autorope/donkeycar/tree/main

tutorial for ros creating packages
https://www.youtube.com/watch?v=iLiI_IRedhI&list=PLuteWQUGtU9BU0sQIVqRQa24p-pSBCYNv&index=3

rplidar and ros
https://www.youtube.com/watch?v=Qrtz0a7HaQ4&list=PLuteWQUGtU9BU0sQIVqRQa24p-pSBCYNv&index=11
https://github.com/NickL77/RPLidar_Hector_SLAM/tree/master

Lista ToDo: 
etapa de robot 2.0
	se espera que el vehiculo este listo para operar y los nodos de control basicos
	se encuentren en su punto de operacion
	
	-servidor de teleoperacion basico                 OK
	-ventilador 5v jetson	                          OK
	-conector xt60 bateria interna                    OK
	-conector xt60 de carga para bateria              OK
	-housing para bateria                             OK
	-ploga con falso contacto                         OK
	-superestructura mejorada facil acceso            OK
	-suspension reforzada                             OK
	-ordenamiento de cableado                         OK
	-checador de bateria y sensores                   OK
	-protector de policarbonato de 6mm                OK
	-polea con liga para Lidar                        OK
	
	-ambiente de ROS                                  OK
	-GPS y nodo                                       OK
	-Reforzar planta motriz							  OK
	-pruebas basicas con kinect						  OK
	-pruebas basicas lidar                            OK
	-encoders hmc5883l, medicion de bateria y nodo    OK

etapa de robot 3.0
	se esperan mejoras adicionales y las primeras pruebas con AI

	-unidad inercial de navegacion
	-AI
	-lamparas
	-SSD externo


cambiar powermode a 10 watts

sudo /usr/sbin/nvpmodel -m 0
https://www.waveshare.com/wiki/Install_ROS_System_on_Jetson_Nano_%26_Environment_Cofiguration

lista de dispositivos serial
lsusb
ls -la /dev/ttyACM*

#ejecutar NEATO xv11

primero seteamos el modo distribuido, esto es, la raspberry correra ROS y
la pc windows se conectara
EN LA RASPERRY O JETSON
export ROS_IP="IP DEL DISPOSITIVO CON LIDAR"
export ROS_MASTER_URI="http://IP DEL DISPOSITIVO CON LIDAR:11311"

EN LA MAQUINA WINDOWS, correr el ejecutable ROS.exe
set ROS_IP=IP DE WINDOWS SIN COMILLAS
!!!!SIN COMILLAS!!!!!!
set ROS_MASTER_URI=http://IP DEL DISPOSITIVO CON LIDAR:11311

EN LA RASPBERRY O JETSON
roscore &              // <<<<<< IMPORTANTE!!!!!
ir al directorio con catkin_ws, en mi caso:
cd ~/JetbotTank/ROS/catkin_ws
agregar los sources para reconocer los nodos actuales
source ./devel/setup.bash
ejecutar el comando de los nodos, en mi caso es este:
y el lidar se encuentra en el puerto /dev/ttyACM1
rosrun xv11_lidarDriver neato_laser_publisher _port:=/dev/ttyACM1 _firmware_version:=2

EN LA MAQUINA WINDOWS
ejecutamos el ambiente rviz
rviz
una vez abierta la interfaz, click en el boton Add (esquina inferior izquierda)
seleccionar la opcion By Display type (esquina superior izquierda del menu que se acaba de abrir)
seleccionar la opcion LaserScan y dar ok
en el nuevo tema de LaserScan que aparecio en la barra lateral izquierda seleccionar en Topic /scan
en la opcion Size, cambiar el valor a 0.05
y en la opcion Fixed Frame de Global Options cambiar map por neato_laser
el mapa debe trazarse de inmediato

en vistas usar TOp to down orto en rviz y setear origen a 0 0 0 X Y Z
instalar paquetes en python ROS.exe

###########################

#comandos de ros usados hasta el momento
printenv | grep ROS                 #imprime las variables de entornon de ROS
#inicializar variables
source /opt/ros/kinetic/setup.bash

Para construir un proyecto existente se utiliza el comando catkin_make

si el directorio ya contiene un subdirectorio src, colocara un CMakeLists.txt en ./src


############### PARA CREAR UN ENTORNO DE  catkin

----------------setear el workspace
http://wiki.ros.org/catkin/Tutorials/create_a_workspace
----------------construir un paquete nuevo TENIENDO YA UN WORKSPACE
http://wiki.ros.org/catkin/Tutorials/CreatingPackage
ejemplo de estructura esperada
workspace_folder/        -- WORKSPACE
  src/                   -- SOURCE SPACE
    CMakeLists.txt       -- 'Toplevel' CMake file, provided by catkin
    package_1/
      CMakeLists.txt     -- CMakeLists.txt file for package_1
      package.xml        -- Package manifest for package_1
    ...
    package_n/
      CMakeLists.txt     -- CMakeLists.txt file for package_n
      package.xml        -- Package manifest for package_n

catkin_create_pkg [name] [dependence1] [dependence2] ...
ejemplo
catkin_create_pkg beginner_tutorials std_msgs rospy roscpp      

despues construir el workspace en el directorio base del workspace de catkin y agregar al entorno
catkin_make
. path/to/current/devel/setup.bash

roscd beginner_tutorials
source ./devel/setup.bash

algunos paquetes externos se tienen que instalar, por ejemplo
sudo apt-get install ros-melodic-serial
sudo apt install qt4-default


########### para correr ros

roscore                 inicia el sistema
rosnode list            lista los nodos actuales del sistema
rostopic list -v        lista los topics actuales
rostopic echo /scan     muestra los mensajes en el topic /scan

rosnode [package_name] [node_name]  ejecuta un nodo y le asigna un nombre
por ejemplo rosrun turtlesim turtlesim_node

######## para ver una grafica con los nodos actuales instalar: <distro> = melodic
$ sudo apt-get install ros-<distro>-rqt
$ sudo apt-get install ros-<distro>-rqt-common-plugins

rosrun rqt_graph rqt_grap

###### desplegar la informacion de un topic
rostopic echo /turtle/cmdvel

########## para correr un nodo que se ha creado, ir a la carpeta donde se ejecuto catkin_make
source ./devel/setup.bash

#### para correr un launch usar por ejemplo
roslaunch hector_slam_launch tutorial.launch               (abre rviz y hector slam)

### ROS Neato xv11 Hector slam lidar example

https://github.com/JanezCim/Neato-XV-11-Hector-SLAM/tree/master

https://github.com/njzhangyifei/xv11-hector-slam-roslaunch

#Related to error timed out. Could not transform laser scan into base_frame.

https://community.husarion.com/t/solved-timed-out-waiting-for-transform-from-base-link-to-map-during-map-navigation/1004/4

seems to be related to sys timeout when distributed mode
https://stackoverflow.com/questions/38983202/how-to-solve-lookup-transform-timed-out-between-various-frames

# ROS image processing
http://wiki.ros.org/stereo_image_proc/Tutorials/Using%20OpenCV%20for%20Image%20Processing
https://dabit-industries.github.io/turtlebot2-tutorials/14c-OpenCV2_CPP.html

pip install cv-bridge
rosrun rqt_image_view rqt_image_view


#Use this command instead to run camera
roslaunch opencv camerav2_320x240.launch enable_raw:=true

#ROS python package tutorial creation
https://roboticsbackend.com/ros-import-python-module-from-another-package/
https://github.com/daniel-robotics/ros_python_pkg/blob/main/scripts/example_py_script
https://answers.ros.org/question/363427/cv_bridge-with-custom-opencv-on-jetson-nano/

#for KINECT follow this tutorial
https://www.youtube.com/watch?v=_QpNMJEAkX0

#start to integrate odometry data
https://answers.ros.org/question/418176/using-odometry-with-motor-encoders-and-visualize-in-rviz/

#Other notes
-noticed that 5v buck regulator only gave 4.9 volt, that would explain the resets when using the camera, recomended
voltage for the 5mm barrel jack should be arround 5.2 volts, installing new regulator

20240717 update 1: it seems that using the power mode:
sudo nvpmodel -m 0
creates a crash condition when attempting to stream from raspicam for example with:
gst-launch-1.0 nvarguscamerasrc ! 'video/x-raw(memory:NVMM),width=3820, height=2464, framerate=21/1, format=NV12' ! nvvidconv flip-method=0 ! 'video/x-raw,width=960, height=616' ! nvvidconv ! nvegltransform ! nveglglessink -e
after a second the raspicam will restart

for now changing to 5w power mode solved the issue
sudo nvpmodel -m 1

lets see if the issue goes off when the new buck converter is installed...
elevating the voltage to 5.15 volts solved the crash condition

- a charge session was monitored, half of the charge detected and 2.5 amp initial current load testing

test run completed successfully, SLAM seems to have problems keeping track of the position in realtime
research for frequence parameters
https://www.youtube.com/watch?v=o9KzTR0vTXk
https://answers.ros.org/question/78776/how-to-prevent-hector_mapping-from-losing-the-position-of-the-robot/
possible clue to how to tune 
https://answers.ros.org/question/263828/how-to-fine-tune-hector-mapping/
hector slam parameter table
https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9506160/
some non tested parameters 
https://github.com/njzhangyifei/xv11-hector-slam-roslaunch/blob/master/default_mapping.launch

value config for tresh angle update
https://robotics.stackexchange.com/questions/63968/the-map-is-incorrect

more example data
https://www.reddit.com/r/ROS/comments/4wxi6w/new_to_ros_having_problems_with_rplidar_and/
http://www.ptolomeo.unam.mx:8080/xmlui/bitstream/handle/132.248.52.100/6467/tesis.pdf?sequence=1&isAllowed=y

returning to default map_update_angle_thresh = 0.9

seems to have problems with handling fast rotations
is there a way to feedback from a IMU ?

attempting to variate map_update_angle_thresh does not improve the accuracy at rotations

increase map resolution????

implementing kinect and opencv research as a final of the current stage
