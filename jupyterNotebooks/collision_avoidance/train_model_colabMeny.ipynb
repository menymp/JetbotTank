{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"train_model_colabMeny.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMks5HxorO+h6HtVfV+e6wg"},"kernelspec":{"name":"python3","display_name":"Python 3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"55479a52594a46bdbcd7ebd1d98e1480":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_1b3b0c617869410aa4bd1b794b2eeda9","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_5f95b0ac54154e13b95d230bd48c15ed","IPY_MODEL_557a1125b14f47edb642a844d324b5cc"]}},"1b3b0c617869410aa4bd1b794b2eeda9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5f95b0ac54154e13b95d230bd48c15ed":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_02c713b640f34415b7a76571172705b8","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":244418560,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":244418560,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a43b5d89091a456e867a7b936fc5d17e"}},"557a1125b14f47edb642a844d324b5cc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_338ce9a813f24d3abe622a83a4519bea","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 233M/233M [00:09&lt;00:00, 24.6MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_987f1a5ee6d44718b0d4c250c2ac1811"}},"02c713b640f34415b7a76571172705b8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"a43b5d89091a456e867a7b936fc5d17e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"338ce9a813f24d3abe622a83a4519bea":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"987f1a5ee6d44718b0d4c250c2ac1811":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"r7LloyTrwabr","colab_type":"text"},"source":["**Collision Avoidance - Train Model**\n","Welcome to this host side Jupyter Notebook! This should look familiar if you ran through the notebooks that run on the robot. In this notebook we'll train our image classifier to detect two classes free and blocked, which we'll use for avoiding collisions. For this, we'll use a popular deep learning library PyTorch\n","**Nota: Hay que activar el entorno con la GPU**"]},{"cell_type":"code","metadata":{"id":"yEkazMnaweRJ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":122},"executionInfo":{"status":"ok","timestamp":1595621064938,"user_tz":360,"elapsed":31039,"user":{"displayName":"luis morales","photoUrl":"","userId":"15107384127336729012"}},"outputId":"52d711cd-b7ae-46ac-c97b-16a18adbd605"},"source":["import torch\n","import torch.optim as optim\n","import torch.nn.functional as F\n","import torchvision\n","import torchvision.datasets as datasets\n","import torchvision.models as models\n","import torchvision.transforms as transforms\n","\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"5YpJcrtGwo9Q","colab_type":"text"},"source":["**Upload and extract dataset**\n","\n","Before you start, you should upload the dataset.zip file that you created in the data_collection.ipynb notebook on the robot.\n","\n","You should then extract this dataset by calling the command below\n","Nota: el contenido se encuentra en la ruta del LS pero para ello se debe montar el drive"]},{"cell_type":"code","metadata":{"id":"cc0dTKorwu6I","colab_type":"code","colab":{}},"source":["#!unzip -q \"/content/drive/My Drive/Tensorflow examples/Jetbot_train/dataset.zip\"\n","#!ls \"/content/drive/My Drive/Tensorflow examples/Jetbot_train/dataset.zip\""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JQSbEfLG0O93","colab_type":"text"},"source":["\n","You should see a folder named dataset appear in the file browser.\n","\n","**Create dataset instance**\n","Now we use the ImageFolder dataset class available with the torchvision.datasets package. We attach transforms from the torchvision.transforms package to prepare the data for training."]},{"cell_type":"code","metadata":{"id":"TKWFzaw30eje","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1595621086380,"user_tz":360,"elapsed":2060,"user":{"displayName":"luis morales","photoUrl":"","userId":"15107384127336729012"}},"outputId":"0bbb9228-553b-41a1-c4d5-c8b63bc505a2"},"source":["!ls \"/content/drive/My Drive/Tensorflow examples/Jetbot_train\""],"execution_count":2,"outputs":[{"output_type":"stream","text":["best_model.pth\tdataset  dataset.zip  train_model_colabMeny.ipynb\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"n4dYfXDn0IBa","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595621169363,"user_tz":360,"elapsed":1913,"user":{"displayName":"luis morales","photoUrl":"","userId":"15107384127336729012"}}},"source":["dataset = datasets.ImageFolder(\n","    '/content/drive/My Drive/Tensorflow examples/Jetbot_train/dataset',\n","    transforms.Compose([\n","        transforms.ColorJitter(0.1, 0.1, 0.1, 0.1),\n","        transforms.Resize((224, 224)),\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","    ])\n",")"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WYS4gRXV1yIR","colab_type":"text"},"source":["**Split dataset into train and test sets**\n","Next, we split the dataset into training and test sets. The test set will be used to verify the accuracy of the model we train."]},{"cell_type":"code","metadata":{"id":"HFr31Q7Rb8wd","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1595621253814,"user_tz":360,"elapsed":393,"user":{"displayName":"luis morales","photoUrl":"","userId":"15107384127336729012"}},"outputId":"5601085c-b363-4102-c891-7cd53b4ec84b"},"source":["print(len(dataset))"],"execution_count":5,"outputs":[{"output_type":"stream","text":["479\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"u9sQi6XW1oRT","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595621312392,"user_tz":360,"elapsed":437,"user":{"displayName":"luis morales","photoUrl":"","userId":"15107384127336729012"}}},"source":["train_dataset, test_dataset = torch.utils.data.random_split(dataset, [len(dataset) - 119, 119])"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"PsxIGfxZcSUt","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1595621348410,"user_tz":360,"elapsed":407,"user":{"displayName":"luis morales","photoUrl":"","userId":"15107384127336729012"}},"outputId":"0833dc54-0b0f-4939-d151-567d0add85ed"},"source":["print(len(train_dataset))"],"execution_count":7,"outputs":[{"output_type":"stream","text":["360\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Ad5ltv4h188_","colab_type":"text"},"source":["\n","**Create data loaders to load data in batches**\n","We'll create two DataLoader instances, which provide utilities for shuffling data, producing batches of images, and loading the samples in parallel with multiple workers."]},{"cell_type":"code","metadata":{"id":"esGgBW1x2CD_","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595621373471,"user_tz":360,"elapsed":379,"user":{"displayName":"luis morales","photoUrl":"","userId":"15107384127336729012"}}},"source":["train_loader = torch.utils.data.DataLoader(\n","    train_dataset,\n","    batch_size=16,\n","    shuffle=True,\n","    num_workers=4\n",")\n","\n","test_loader = torch.utils.data.DataLoader(\n","    test_dataset,\n","    batch_size=16,\n","    shuffle=True,\n","    num_workers=4\n",")"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5ocBQui-2Nym","colab_type":"text"},"source":["\n","**Define the neural network**\n","Now, we define the neural network we'll be training. The torchvision package provides a collection of pre-trained models that we can use.\n","\n","In a process called transfer learning, we can repurpose a pre-trained model (trained on millions of images) for a new task that has possibly much less data available.\n","\n","Important features that were learned in the original training of the pre-trained model are re-usable for the new task. We'll use the alexnet model."]},{"cell_type":"code","metadata":{"id":"ax0H-E3O2UBN","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":83,"referenced_widgets":["55479a52594a46bdbcd7ebd1d98e1480","1b3b0c617869410aa4bd1b794b2eeda9","5f95b0ac54154e13b95d230bd48c15ed","557a1125b14f47edb642a844d324b5cc","02c713b640f34415b7a76571172705b8","a43b5d89091a456e867a7b936fc5d17e","338ce9a813f24d3abe622a83a4519bea","987f1a5ee6d44718b0d4c250c2ac1811"]},"executionInfo":{"status":"ok","timestamp":1595621395847,"user_tz":360,"elapsed":10940,"user":{"displayName":"luis morales","photoUrl":"","userId":"15107384127336729012"}},"outputId":"675f9292-f7c0-44eb-a4e0-612e980ce8d0"},"source":["model = models.alexnet(pretrained=True)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Downloading: \"https://download.pytorch.org/models/alexnet-owt-4df8aa71.pth\" to /root/.cache/torch/checkpoints/alexnet-owt-4df8aa71.pth\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"55479a52594a46bdbcd7ebd1d98e1480","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=244418560.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"cSwVXMAt2dDV","colab_type":"text"},"source":["The alexnet model was originally trained for a dataset that had 1000 class labels, but our dataset only has two class labels! We'll replace the final layer with a new, untrained layer that has only two outputs"]},{"cell_type":"code","metadata":{"id":"2bnYYfIr2gzF","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595621401785,"user_tz":360,"elapsed":416,"user":{"displayName":"luis morales","photoUrl":"","userId":"15107384127336729012"}}},"source":["model.classifier[6] = torch.nn.Linear(model.classifier[6].in_features, 2)"],"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0YlLtdh62oSU","colab_type":"text"},"source":["Finally, we transfer our model for execution on the GPU"]},{"cell_type":"code","metadata":{"id":"Fp8XclNh2ub8","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595621421804,"user_tz":360,"elapsed":10058,"user":{"displayName":"luis morales","photoUrl":"","userId":"15107384127336729012"}}},"source":["device = torch.device('cuda')\n","model = model.to(device)"],"execution_count":11,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FfTNnBID3yfx","colab_type":"text"},"source":["\n","**Train the neural network**\n","Using the code below we will train the neural network for 30 epochs, saving the best performing model after each epoch.\n","\n","An epoch is a full run through our data."]},{"cell_type":"code","metadata":{"id":"kOyQrTvo34Lm","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":527},"executionInfo":{"status":"ok","timestamp":1595621614242,"user_tz":360,"elapsed":174913,"user":{"displayName":"luis morales","photoUrl":"","userId":"15107384127336729012"}},"outputId":"0095e867-838a-47e9-f64b-2528eadb5b2f"},"source":["NUM_EPOCHS = 30\n","BEST_MODEL_PATH = '/content/drive/My Drive/Tensorflow examples/Jetbot_train/best_model.pth'\n","best_accuracy = 0.0\n","\n","optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n","\n","for epoch in range(NUM_EPOCHS):\n","    \n","    for images, labels in iter(train_loader):\n","        images = images.to(device)\n","        labels = labels.to(device)\n","        optimizer.zero_grad()\n","        outputs = model(images)\n","        loss = F.cross_entropy(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","    \n","    test_error_count = 0.0\n","    for images, labels in iter(test_loader):\n","        images = images.to(device)\n","        labels = labels.to(device)\n","        outputs = model(images)\n","        test_error_count += float(torch.sum(torch.abs(labels - outputs.argmax(1))))\n","    \n","    test_accuracy = 1.0 - float(test_error_count) / float(len(test_dataset))\n","    print('%d: %f' % (epoch, test_accuracy))\n","    if test_accuracy > best_accuracy:\n","        torch.save(model.state_dict(), BEST_MODEL_PATH)\n","        best_accuracy = test_accuracy"],"execution_count":12,"outputs":[{"output_type":"stream","text":["0: 0.857143\n","1: 0.907563\n","2: 0.941176\n","3: 0.907563\n","4: 0.924370\n","5: 0.949580\n","6: 0.932773\n","7: 0.932773\n","8: 0.941176\n","9: 0.949580\n","10: 0.949580\n","11: 0.915966\n","12: 0.966387\n","13: 0.949580\n","14: 0.949580\n","15: 0.941176\n","16: 0.924370\n","17: 0.932773\n","18: 0.949580\n","19: 0.932773\n","20: 0.924370\n","21: 0.932773\n","22: 0.949580\n","23: 0.949580\n","24: 0.949580\n","25: 0.957983\n","26: 0.957983\n","27: 0.949580\n","28: 0.941176\n","29: 0.949580\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"OZYS9TFr5K8B","colab_type":"text"},"source":["Once that is finished, you should see a file best_model.pth in the Jupyter Lab file browser. Select Right click -> Download to download the model to your workstation"]}]}